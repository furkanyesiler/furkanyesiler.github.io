---
title: "Projects"
excerpt_separator: "<!--more-->"
permalink: /projects/
read_time: false
related: false
---
<h2></h2>

**Re-MOVE**
<br/><span style="font-size:0.8em;">[**[Github]**](https://github.com/furkanyesiler/re-move)
<br/>Re-MOVE (Reduced MOVE) is a neural network model that is trained with embedding distillation techniques to further improve both the accuracy and the scalability aspects of MOVE. This repository contains the training/evaluation code and the pre-trained model weights.
<br/>**Keywords**: Python, PyTorch, embedding distillation, knowledge distillation, neural network pruning, dimensionality reduction, metric learning.</span>

**MOVE**
<br/><span style="font-size:0.8em;">[**[Github]**](https://github.com/furkanyesiler/move)
<br/>MOVE, or musically-motivated version embeddings, is a convolutional neural network model that demonstrates state-of-the-art performance in version identification task. It is designed to achieve invariances against changes in pitch transpositions, tempo/timing, and structure.
<br/>**Keywords**: Python, PyTorch, invariant representations, neural network encoder, attention, metric learning, data augmentations.</span>

**Da-TACOS**
<br/><span style="font-size:0.8em;">[**[Github]**](https://github.com/MTG/da-tacos)
<br/>Da-TACOS is a dataset for cover song identification and understanding, which contains various pre-extracted features for 25k songs. The feature extraction and benchmarking are performed using the “acoss” framework that is specifically designed for this task.
<br/>**Keywords**: Python, audio signal processing, open science.</span>

**PhonationRT**
<br/><span style="font-size:0.8em;">[**[Github]**](https://github.com/furkanyesiler/PhonationModes-MasterThesis)
<br/>PhonationRT is a visual feedback prototype for learning/teaching phonation modes in singing.
<br/>**Keywords**: C++, Qt Creator, Weka.</span>